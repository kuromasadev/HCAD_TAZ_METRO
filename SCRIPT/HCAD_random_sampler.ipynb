{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f839a47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import random\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "from datetime import datetime\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import urllib3\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "\n",
    "\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "045741da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output directory\n",
    "output_dir = \"OUTPUT/HCAD_SAMPLES\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "932764dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base URL for parcel endpoint\n",
    "url = \"https://arcweb.hcad.org/server/rest/services/public/public_query/MapServer/0/query\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21690cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metro service area polygon (as GeoSeries or single unified geometry)\n",
    "metro_gdf = gpd.read_file(\"../REF\\Metro_MTA_Tax_Area.geojson\")\n",
    "metro_union = metro_gdf.union_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2683f547",
   "metadata": {},
   "source": [
    "# Collect Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4faeb709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_random_sample(metro_union, target_count=1000, batch_size=500, max_attempts=20, output_dir=\"OUTPUT\"):\n",
    "    # 1. Get all parcel object IDs\n",
    "    url = \"https://arcweb.hcad.org/server/rest/services/public/public_query/MapServer/0/query\"\n",
    "    id_params = {\n",
    "        \"where\": \"1=1\",\n",
    "        \"returnIdsOnly\": \"true\",\n",
    "        \"f\": \"json\"\n",
    "    }\n",
    "    id_response = requests.get(url, params=id_params, verify=False)\n",
    "    all_ids = id_response.json().get(\"objectIds\", [])\n",
    "    \n",
    "    if not all_ids:\n",
    "        raise ValueError(\"No ObjectIDs returned from HCAD endpoint.\")\n",
    "    \n",
    "    # 2. Resampling logic\n",
    "    final_records = []\n",
    "    final_geometries = []\n",
    "    used_ids = set()\n",
    "    attempts = 0\n",
    "\n",
    "    def fetch_and_filter(batch_size=500):\n",
    "        remaining_ids = list(set(all_ids) - used_ids)\n",
    "        if not remaining_ids:\n",
    "            return\n",
    "\n",
    "        sample_ids = random.sample(remaining_ids, min(batch_size, len(remaining_ids)))\n",
    "        query_params = {\n",
    "            \"objectIds\": \",\".join(map(str, sample_ids)),\n",
    "            \"outFields\": \"*\",\n",
    "            \"returnGeometry\": \"true\",\n",
    "            \"f\": \"json\",\n",
    "            \"outSR\": \"4326\"\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, params=query_params, verify=False)\n",
    "        features = response.json().get(\"features\", [])\n",
    "\n",
    "        for feature in features:\n",
    "            oid = feature.get(\"attributes\", {}).get(\"OBJECTID\")\n",
    "            if oid in used_ids:\n",
    "                continue\n",
    "\n",
    "            rings = feature.get(\"geometry\", {}).get(\"rings\", [])\n",
    "            if rings and isinstance(rings, list) and len(rings[0]) > 2:\n",
    "                try:\n",
    "                    polygon = Polygon(rings[0])\n",
    "                    if polygon.intersects(metro_union):\n",
    "                        final_records.append(feature[\"attributes\"])\n",
    "                        final_geometries.append(polygon)\n",
    "                        used_ids.add(oid)\n",
    "                except Exception:\n",
    "                    continue\n",
    "\n",
    "    while len(final_records) < target_count and attempts < max_attempts:\n",
    "        fetch_and_filter(batch_size)\n",
    "        attempts += 1\n",
    "        print(f\"Collected {len(final_records)} valid records (attempt {attempts})\")\n",
    "\n",
    "    if not final_geometries:\n",
    "        raise ValueError(\"No valid geometries found in sampling process.\")\n",
    "\n",
    "    final_gdf = gpd.GeoDataFrame(final_records, geometry=final_geometries, crs=\"EPSG:4326\")\n",
    "\n",
    "    # Add a stable unique ID for each record using a hash of the HCAD_NUM\n",
    "    final_gdf[\"unique_id\"] = final_gdf.apply(lambda row: hashlib.md5(str(row.get(\"HCAD_NUM\")).encode()).hexdigest(), axis=1)\n",
    "\n",
    "    # Metadata\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    timestamp_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    sampleset_id = f\"sampleset_{timestamp_str}\"\n",
    "    metadata = {\n",
    "        \"timestamp\": timestamp,\n",
    "        \"sampling_batch_size\": batch_size,\n",
    "        \"total_properties_sampled\": len(final_gdf),\n",
    "        \"sampling_attempts\": attempts,\n",
    "        \"samplesetID\": sampleset_id\n",
    "    }\n",
    "\n",
    "    # Save with metadata\n",
    "    timestamp_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"metro_intersecting_parcels_{timestamp_str}.geojson\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    geojson_obj = json.loads(final_gdf.to_json())\n",
    "    geojson_obj[\"metadata\"] = metadata\n",
    "\n",
    "    with open(filepath, \"w\") as f:\n",
    "        json.dump(geojson_obj, f)\n",
    "\n",
    "    return final_gdf, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c798967",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samples = []\n",
    "\n",
    "independent_sample_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62c83558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 394 valid records (attempt 1)\n",
      "Collected 807 valid records (attempt 2)\n",
      "Collected 1210 valid records (attempt 3)\n",
      "Collected 403 valid records (attempt 1)\n",
      "Collected 802 valid records (attempt 2)\n",
      "Collected 1220 valid records (attempt 3)\n",
      "Collected 403 valid records (attempt 1)\n",
      "Collected 806 valid records (attempt 2)\n",
      "Collected 1217 valid records (attempt 3)\n",
      "Collected 422 valid records (attempt 1)\n",
      "Collected 829 valid records (attempt 2)\n",
      "Collected 1242 valid records (attempt 3)\n",
      "Collected 408 valid records (attempt 1)\n",
      "Collected 804 valid records (attempt 2)\n",
      "Collected 1198 valid records (attempt 3)\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    gdf, metadata = run_random_sample(metro_union)\n",
    "    all_samples.append((gdf, metadata))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0787596",
   "metadata": {},
   "source": [
    "# Combine all Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16f9c2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder where your sample files are saved\n",
    "sample_dir = \"OUTPUT/HCAD_SAMPLES\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c2e7ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all GeoJSONs that match pattern\n",
    "sample_files = [f for f in os.listdir(sample_dir) if f.endswith(\".geojson\") and f.startswith(\"metro_intersecting_parcels_\")]\n",
    "\n",
    "# Initialize container\n",
    "all_gdfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58fb54b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in sample_files:\n",
    "    filepath = os.path.join(sample_dir, file)\n",
    "\n",
    "    with open(filepath, \"r\") as f:\n",
    "        geojson_data = json.load(f)\n",
    "\n",
    "    metadata = geojson_data.get(\"metadata\", {})\n",
    "    gdf = gpd.GeoDataFrame.from_features(geojson_data[\"features\"])\n",
    "    gdf.set_crs(\"EPSG:4326\", inplace=True)\n",
    "\n",
    "    # Attach metadata as columns\n",
    "    for key, value in metadata.items():\n",
    "        gdf[key] = value\n",
    "\n",
    "    # Extract sample_id from filename or timestamp\n",
    "    match = re.search(r\"_(\\d{8}_\\d{6})\", file)\n",
    "    sample_id = match.group(1) if match else file\n",
    "    gdf[\"sample_id\"] = sample_id\n",
    "\n",
    "    all_gdfs.append(gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f80691c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate\n",
    "combined_gdf = gpd.GeoDataFrame(pd.concat(all_gdfs, ignore_index=True), crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68f53832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add index column\n",
    "combined_gdf.reset_index(inplace=True)\n",
    "combined_gdf.rename(columns={\"index\": \"parcel_index\"}, inplace=True)\n",
    "\n",
    "# Save for next steps\n",
    "combined_gdf.to_file(\"OUTPUT/combined_random_samples.geojson\", driver=\"GeoJSON\")\n",
    "combined_gdf.to_parquet(\"OUTPUT/combined_random_samples.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e6aaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea60162",
   "metadata": {},
   "source": [
    "# All Samples Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14571799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium import GeoJson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b56c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(location=[29.76, -95.37], zoom_start=11, tiles=\"cartodbpositron\")\n",
    "\n",
    "for _, row in combined_gdf.iterrows():\n",
    "    sim_geo = gpd.GeoSeries([row.geometry]).__geo_interface__\n",
    "    folium.GeoJson(sim_geo).add_to(m)\n",
    "\n",
    "m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

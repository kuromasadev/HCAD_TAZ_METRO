{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22439853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from io import StringIO\n",
    "import sqlite3\n",
    "import csv\n",
    "import geopandas as gpd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31e9287",
   "metadata": {},
   "source": [
    "# Step 2A : Match Combined Random Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2581b916",
   "metadata": {},
   "source": [
    "HCAD Account Number with Polygons\n",
    "\n",
    "Download Real Property from HCAD : http://hcad.org/pdata/pdata-property-downloads.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739d5fab",
   "metadata": {},
   "source": [
    "Real Property Data from 2025 is ~890MB, data split out available in chunked txt files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed870ecb",
   "metadata": {},
   "source": [
    "##### *To recreate original file*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f372d09d",
   "metadata": {},
   "source": [
    "\n",
    "``` python\n",
    "def load_real_property_chunks_safe(folder_path, delimiter='\\t', log_bad_lines=True):\n",
    "    files = sorted([\n",
    "        f for f in os.listdir(folder_path)\n",
    "        if f.startswith('real_acct_2025') and f.endswith('.txt')\n",
    "    ])\n",
    "    \n",
    "    data_rows = []\n",
    "    header = None\n",
    "    bad_lines = []\n",
    "\n",
    "    for file in files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "            lines = f.readlines()\n",
    "            if header is None:\n",
    "                header = lines[0].strip().split(delimiter)\n",
    "                expected_cols = len(header)\n",
    "            for i, line in enumerate(lines[1:], start=2):  # Start from line 2 in human terms\n",
    "                parts = line.strip().split(delimiter)\n",
    "                if len(parts) == expected_cols:\n",
    "                    data_rows.append(parts)\n",
    "                else:\n",
    "                    if log_bad_lines:\n",
    "                        bad_lines.append((file, i, len(parts), line.strip()))\n",
    "    \n",
    "    # Create DataFrame\n",
    "    HCAD_RealProperty = pd.DataFrame(data_rows, columns=header)\n",
    "\n",
    "    # Optionally print or log bad lines\n",
    "    if log_bad_lines and bad_lines:\n",
    "        print(f\"\\nSkipped {len(bad_lines)} malformed rows:\")\n",
    "        for file, lineno, cols, preview in bad_lines[:10]:  # show only first 10\n",
    "            print(f\"{file}, line {lineno}: expected {expected_cols}, found {cols} columns — {preview[:100]}...\")\n",
    "\n",
    "    return HCAD_RealProperty\n",
    "```\n",
    "\n",
    "HCAD_RealProperty = load_real_property_chunks_safe(\"../2025_RPD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ae3c2f",
   "metadata": {},
   "source": [
    "## Real Property Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58b60295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Real Property Data column names\n",
    "columns = [\n",
    "    \"acct\", \"yr\", \"mailto\", \"mail_addr_1\", \"mail_addr_2\", \"mail_city\", \"mail_state\", \"mail_zip\", \"mail_country\",\n",
    "    \"undeliverable\", \"str_pfx\", \"str_num\", \"str_num_sfx\", \"str\", \"str_sfx\", \"str_sfx_dir\", \"str_unit\",\n",
    "    \"site_addr_1\", \"site_addr_2\", \"site_addr_3\", \"state_class\", \"school_dist\", \"map_facet\", \"key_map\",\n",
    "    \"Neighborhood_Code\", \"Neighborhood_Grp\", \"Market_Area_1\", \"Market_Area_1_Dscr\", \"Market_Area_2\",\n",
    "    \"Market_Area_2_Dscr\", \"econ_area\", \"econ_bld_class\", \"center_code\", \"yr_impr\", \"yr_annexed\", \"splt_dt\",\n",
    "    \"dsc_cd\", \"nxt_bld\", \"bld_ar\", \"land_ar\", \"acreage\", \"Cap_acct\", \"shared_cad\", \"land_val\", \"bld_val\",\n",
    "    \"x_features_val\", \"ag_val\", \"assessed_val\", \"tot_appr_val\", \"tot_mkt_val\", \"prior_land_val\",\n",
    "    \"prior_bld_val\", \"prior_x_features_val\", \"prior_ag_val\", \"prior_tot_appr_val\", \"prior_tot_mkt_val\",\n",
    "    \"new_construction_val\", \"tot_rcn_val\", \"value_status\", \"noticed\", \"notice_dt\", \"protested\",\n",
    "    \"certified_date\", \"rev_dt\", \"rev_by\", \"new_own_dt\", \"lgl_1\", \"lgl_2\", \"lgl_3\", \"lgl_4\", \"jurs\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04c7cd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_realacct_to_sqlite(txt_file, db_file, table_name, delimiter='\\t'):\n",
    "    conn = sqlite3.connect(db_file)\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Drop and create table with appropriate schema\n",
    "    cur.execute(f'DROP TABLE IF EXISTS {table_name}')\n",
    "    col_defs = ', '.join([f'\"{col}\" TEXT' for col in columns])\n",
    "    cur.execute(f'CREATE TABLE {table_name} ({col_defs})')\n",
    "\n",
    "    # Insert valid rows in chunks\n",
    "    placeholders = ','.join(['?'] * len(columns))\n",
    "    with open(txt_file, 'r', encoding='utf-8', errors='replace') as f:\n",
    "        reader = csv.reader(f, delimiter=delimiter)\n",
    "        header = next(reader)  # Skip header in file\n",
    "\n",
    "        batch = []\n",
    "        for row in reader:\n",
    "            if len(row) == len(columns):\n",
    "                batch.append(row)\n",
    "                if len(batch) >= 10000:\n",
    "                    cur.executemany(f'INSERT INTO {table_name} VALUES ({placeholders})', batch)\n",
    "                    batch = []\n",
    "        if batch:\n",
    "            cur.executemany(f'INSERT INTO {table_name} VALUES ({placeholders})', batch)\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(f\"Loaded data into table '{table_name}' in '{db_file}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2cf79e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data into table 'HCAD_RealProperty' in 'real_property.db'.\n"
     ]
    }
   ],
   "source": [
    "# Load Data into Sqlite\n",
    "load_realacct_to_sqlite('../2025_RPD/real_acct.txt', 'real_property.db', 'HCAD_RealProperty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeac00c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL Connect\n",
    "conn = sqlite3.connect('real_property.db')\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc0ff73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"\n",
    "CREATE VIEW IF NOT EXISTS HCAD_RealProperty_View AS\n",
    "SELECT\n",
    "    acct,\n",
    "    mail_city,\n",
    "    state_class,\n",
    "    school_dist,\n",
    "    Neighborhood_Code,\n",
    "    Neighborhood_Grp,\n",
    "    Market_Area_1,\n",
    "    Market_Area_1_Dscr,\n",
    "    Market_Area_2,\n",
    "    Market_Area_2_Dscr,\n",
    "    econ_area,\n",
    "    econ_bld_class,\n",
    "    center_code,\n",
    "    yr_impr,\n",
    "    yr_annexed,\n",
    "    splt_dt,\n",
    "    dsc_cd,\n",
    "    acreage,\n",
    "    land_val,\n",
    "    bld_val,\n",
    "    x_features_val,\n",
    "    ag_val,\n",
    "    assessed_val,\n",
    "    tot_appr_val,\n",
    "    tot_mkt_val\n",
    "FROM HCAD_RealProperty;\n",
    "\"\"\")\n",
    "\n",
    "# Commit\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1aa03051",
   "metadata": {},
   "outputs": [],
   "source": [
    "HCAD_RealProperty = pd.read_sql_query(\"SELECT * FROM HCAD_RealProperty_View\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca39058e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78271e8",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8fa31dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_allsamples = gpd.read_file(\"OUTPUT\\combined_random_samples.geojson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387d0eb1",
   "metadata": {},
   "source": [
    "temp step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "468ef4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HCAD_NUM samples from gdf:\n",
      "['1274410000036' '1152790430005' '1219740030067' '1416470010001'\n",
      " '0432120010343']\n"
     ]
    }
   ],
   "source": [
    "print(\"HCAD_NUM samples from gdf:\")\n",
    "print(gdf_allsamples[\"HCAD_NUM\"].dropna().astype(str).unique()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9eb45253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "acct samples from HCAD_RealProperty:\n",
      "['0010010000013            ' '0010020000001            '\n",
      " '0010020000003            ' '0010020000004            '\n",
      " '0010020000013            ']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nacct samples from HCAD_RealProperty:\")\n",
    "print(HCAD_RealProperty[\"acct\"].dropna().astype(str).unique()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba9aa170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching account count: 0 of 6076 in gdf\n"
     ]
    }
   ],
   "source": [
    "gdf_accts = set(gdf_allsamples[\"HCAD_NUM\"].dropna().astype(str))\n",
    "db_accts = set(HCAD_RealProperty[\"acct\"].dropna().astype(str))\n",
    "\n",
    "common = gdf_accts & db_accts\n",
    "print(f\"Matching account count: {len(common)} of {len(gdf_accts)} in gdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f24655fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_allsamples[\"HCAD_NUM_clean\"] = gdf_allsamples[\"HCAD_NUM\"].astype(str).str.strip().str.zfill(13)  # example padding\n",
    "HCAD_RealProperty[\"acct_clean\"] = HCAD_RealProperty[\"acct\"].astype(str).str.strip().str.zfill(13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39236f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches after cleaning: 6072\n"
     ]
    }
   ],
   "source": [
    "common_clean = set(gdf_allsamples[\"HCAD_NUM_clean\"]) & set(HCAD_RealProperty[\"acct_clean\"])\n",
    "print(f\"Matches after cleaning: {len(common_clean)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebae69f7",
   "metadata": {},
   "source": [
    "actual join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6749effc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_joined = gdf_allsamples.merge(HCAD_RealProperty, \n",
    "                                  left_on=\"HCAD_NUM_clean\", \n",
    "                                  right_on=\"acct_clean\", \n",
    "                                  how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "582a7144",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\"parcel_type\", \n",
    "                   \"yr_annexed\", \n",
    "                   \"splt_dt\", \n",
    "                   \"dsc_cd\",\n",
    "                   \"timestamp\",\n",
    "                   \"sampling_batch_size\",\n",
    "                   \"total_properties_sampled\",\n",
    "                   \"sampling_attempts\",\n",
    "                   \"samplesetID\"\n",
    "                   ]\n",
    "gdf_joined = gdf_joined.drop(columns=columns_to_drop, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ec45b6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "front_cols = [\n",
    "    'parcel_index', \n",
    "    'unique_id', # unique record ID\n",
    "    'sample_id', # sample set identifier\n",
    "    'HCAD_NUM', \n",
    "    'HCAD_NUM_clean', \n",
    "    'acct_clean',\n",
    "    'city', \n",
    "    'mail_city', \n",
    "    'state_class_y', \n",
    "    'state_class_x',\n",
    "    'appr_val', \n",
    "    'tot_appr_val', \n",
    "    'mkt_val', \n",
    "    'tot_mkt_val'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "00b96a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_cols = [col for col in gdf_joined.columns if col not in front_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9129bf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_joined = gdf_joined[front_cols + remaining_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0bce16",
   "metadata": {},
   "source": [
    "#### Data Type Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "08c9c667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to convert\n",
    "currency_cols = ['appr_val', 'tot_appr_val', 'mkt_val', 'tot_mkt_val']\n",
    "conversion_report = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9b61e2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Conversion\n",
    "for col in currency_cols:\n",
    "    if col in gdf_joined.columns:\n",
    "        original_nulls = gdf_joined[col].isna().sum()\n",
    "        original_type = gdf_joined[col].dtype\n",
    "\n",
    "        # Clean and convert\n",
    "        gdf_joined[col] = (\n",
    "            gdf_joined[col]\n",
    "            .replace('', '0')             # Replace empty strings with '0'\n",
    "            .replace(' ', '0')            # Replace space-only strings too\n",
    "            .fillna(0)                    # Fill any remaining NaNs\n",
    "            .astype(float)                # Convert to float\n",
    "            .round(2)\n",
    "        )\n",
    "\n",
    "        # Confirmation\n",
    "        conversion_report[col] = {\n",
    "            'original_dtype': str(original_type),\n",
    "            'nulls_filled': original_nulls,\n",
    "            'total_records': len(gdf_joined)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b72774a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currency Conversion Summary:\n",
      " - appr_val: 12174 rows processed | 610 nulls filled | original type was float64\n",
      " - tot_appr_val: 12174 rows processed | 8 nulls filled | original type was object\n",
      " - mkt_val: 12174 rows processed | 610 nulls filled | original type was float64\n",
      " - tot_mkt_val: 12174 rows processed | 8 nulls filled | original type was object\n"
     ]
    }
   ],
   "source": [
    "# Print conversion report\n",
    "print(\"Currency Conversion Summary:\")\n",
    "for col, stats in conversion_report.items():\n",
    "    print(f\" - {col}: {stats['total_records']} rows processed | {stats['nulls_filled']} nulls filled | original type was {stats['original_dtype']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bf18c9",
   "metadata": {},
   "source": [
    "#### Integrity Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "83f82e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatch_report = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "38bd9480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_and_cleanup(col1, col2, drop_col_if_match, rename_if_match=None):\n",
    "    global gdf_joined\n",
    "    total = len(gdf_joined)\n",
    "\n",
    "    if col1 not in gdf_joined.columns or col2 not in gdf_joined.columns:\n",
    "        print(f\"Warning: One or both columns missing: {col1}, {col2}\")\n",
    "        return\n",
    "\n",
    "    if (gdf_joined[col1] == gdf_joined[col2]).all():\n",
    "        if drop_col_if_match and drop_col_if_match in gdf_joined.columns:\n",
    "            gdf_joined.drop(columns=[drop_col_if_match], inplace=True)\n",
    "        if rename_if_match:\n",
    "            gdf_joined.rename(columns={col2: rename_if_match}, inplace=True)\n",
    "    else:\n",
    "        mismatch_count = (gdf_joined[col1] != gdf_joined[col2]).sum()\n",
    "        mismatch_report[f\"{col1} vs {col2}\"] = {\n",
    "            \"count\": mismatch_count,\n",
    "            \"percent\": round((mismatch_count / total) * 100, 2)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a2469c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HCAD_NUM comparisons\n",
    "check_and_cleanup(\"HCAD_NUM\", \"HCAD_NUM_clean\", drop_col_if_match=\"HCAD_NUM_clean\")\n",
    "check_and_cleanup(\"HCAD_NUM\", \"acct_clean\", drop_col_if_match=\"acct_clean\")\n",
    "\n",
    "# State class comparison\n",
    "check_and_cleanup(\"state_class_y\", \"state_class_x\", drop_col_if_match=\"state_class_x\", rename_if_match=\"state_class\")\n",
    "\n",
    "# Appraised value\n",
    "check_and_cleanup(\"appr_val\", \"tot_appr_val\", drop_col_if_match=\"appr_val\")\n",
    "\n",
    "# Market value\n",
    "check_and_cleanup(\"mkt_val\", \"tot_mkt_val\", drop_col_if_match=\"mkt_val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "02d47bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column Mismatches Found:\n",
      "HCAD_NUM vs acct_clean: 8 records do not match (0.07% of total)\n",
      "state_class_y vs state_class_x: 1162 records do not match (9.54% of total)\n",
      "appr_val vs tot_appr_val: 14 records do not match (0.11% of total)\n",
      "mkt_val vs tot_mkt_val: 14 records do not match (0.11% of total)\n"
     ]
    }
   ],
   "source": [
    "# Print mismatch report if any\n",
    "if mismatch_report:\n",
    "    print(\"\\nColumn Mismatches Found:\")\n",
    "    for k, stats in mismatch_report.items():\n",
    "        print(f\"{k}: {stats['count']} records do not match ({stats['percent']}% of total)\")\n",
    "else:\n",
    "    print(\"All compared columns are fully aligned; cleanup applied.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b606d1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_joined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd98b97d",
   "metadata": {},
   "source": [
    "# Step 2B : Sample Matching Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3eee41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save point\n",
    "gdf_joined.to_file(\"OUTPUT/gdf_joined_output.geojson\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71fcd120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Save Point, re-load all geospatial files\n",
    "metro_boundary = gpd.read_file(\"../REF/Metro_MTA_Tax_Area.geojson\")\n",
    "metro_RRC = gpd.read_file(\"../REF/METRO_RailRoadCrossings.geojson\")\n",
    "metro_BB = gpd.read_file(\"../REF/METRO_TxDOT_Bridges.geojson\")\n",
    "\n",
    "metro_TC = gpd.read_file(\"../REF/Metro_Transit_Centers.geojson\")\n",
    "metro_PnR = gpd.read_file(\"../REF/Metro_Park_and_Rides.geojson\")\n",
    "metro_LRT = gpd.read_file(\"../REF/Metro_LRT_Stations.geojson\")\n",
    "\n",
    "metro_rs_gdf = gpd.read_file(\"OUTPUT/gdf_joined_output.geojson\")\n",
    "\n",
    "# Clearnin up Raw Data Import\n",
    "pnr_col2k = [\"OBJECTID\",\n",
    "             \"ADDRESS\",\n",
    "             \"ROUTES_SER\",\n",
    "             \"geometry\"\n",
    "            ]\n",
    "metro_PnR = metro_PnR[pnr_col2k]\n",
    "metro_TC = metro_TC[pnr_col2k]\n",
    "\n",
    "lrt_col2k = [\"OBJECTID\",\n",
    "             \"Stat_Name\",\n",
    "             \"Stat_Loc\",\n",
    "             \"LineColor\",\n",
    "             \"geometry\"\n",
    "            ]\n",
    "metro_LRT = metro_LRT[lrt_col2k]\n",
    "\n",
    "bb_col2k = [\"BRDG_ID\",\n",
    "            \"FEAT_INTSECTD\",\n",
    "            \"FACLTY_CARRD_BY_STRUC\",\n",
    "            \"YR_BLT\",\n",
    "            \"ADT\",\n",
    "            \"ADT_YR\",\n",
    "            \"ADT_TRK\",\n",
    "            \"LT_SDWALK_WIDTH\",\n",
    "            \"RT_SDWALK_WIDTH\",\n",
    "            \"FUT_ADT\",\n",
    "            \"FUT_ADT_YR\",\n",
    "            \"BRDG_DESC\",\n",
    "            \"geometry\"\n",
    "            ]\n",
    "metro_BB = metro_BB[bb_col2k]\n",
    "\n",
    "rrc_col2k = [\"CrossingID\",\n",
    "             \"Street\",\n",
    "             \"TtstnNam\",\n",
    "             \"TypeXing\",\n",
    "             \"Railroad\",\n",
    "             \"geometry\"\n",
    "             ]\n",
    "metro_RRC = metro_RRC[rrc_col2k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2eed27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_overlay_analysis(parcel_gdf, features):\n",
    "    # Project all layers to a suitable linear CRS (Houston = EPSG:2278)\n",
    "    crs_proj = \"EPSG:2278\"\n",
    "    parcel_gdf = parcel_gdf.to_crs(crs_proj)\n",
    "    for key in features:\n",
    "        features[key] = features[key].to_crs(crs_proj)\n",
    "\n",
    "    # Distance to nearest transit access points\n",
    "    parcel_gdf[\"dist_to_tcenter\"] = parcel_gdf.geometry.apply(lambda x: features[\"tcenter\"].distance(x).min())\n",
    "    parcel_gdf[\"dist_to_parkride\"] = parcel_gdf.geometry.apply(lambda x: features[\"parkride\"].distance(x).min())\n",
    "    parcel_gdf[\"dist_to_lrt\"] = parcel_gdf.geometry.apply(lambda x: features[\"lrt\"].distance(x).min())\n",
    "\n",
    "    # Barrier analysis: 1-mile buffer (1609 meters)\n",
    "    buffer_1mile = parcel_gdf.geometry.buffer(1609)\n",
    "    parcel_gdf[\"barrier_bridges\"] = [features[\"bridges\"].intersects(b).sum() for b in buffer_1mile]\n",
    "    parcel_gdf[\"barrier_rxings\"] = [features[\"rrc\"].intersects(b).sum() for b in buffer_1mile]\n",
    "\n",
    "    # Accessibility analysis: ¼-mile buffer (402 meters)\n",
    "    buffer_quarter = parcel_gdf.geometry.buffer(402)\n",
    "    parcel_gdf[\"access_tcenter_qtrmi\"] = [features[\"tcenter\"].intersects(b).sum() for b in buffer_quarter]\n",
    "    parcel_gdf[\"access_parkride_qtrmi\"] = [features[\"parkride\"].intersects(b).sum() for b in buffer_quarter]\n",
    "    parcel_gdf[\"access_lrt_qtrmi\"] = [features[\"lrt\"].intersects(b).sum() for b in buffer_quarter]\n",
    "\n",
    "    return parcel_gdf.to_crs(\"EPSG:4326\")  # Restore to geographic coordinates for export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7508210",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dict = {\n",
    "    \"tcenter\": metro_TC,\n",
    "    \"parkride\": metro_PnR,\n",
    "    \"lrt\": metro_LRT,\n",
    "    \"bridges\": metro_BB,\n",
    "    \"rrc\": metro_RRC\n",
    "}\n",
    "\n",
    "metro_rs_gdf_overlay = apply_overlay_analysis(metro_rs_gdf, features_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a06666e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlay Save Point result\n",
    "metro_rs_gdf_overlay.to_file(\"OUTPUT/metro_rs_overlay.geojson\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0326236",
   "metadata": {},
   "outputs": [],
   "source": [
    "metro_rs_gdf_overlay"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
